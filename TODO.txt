### ZOOM ###

Personal (TUE 12h00)
  https://mcgill.zoom.us/j/99190128309
Lab (THU 11h00) 
  https://mcgill.zoom.us/j/94813175403

### INFORMATION ###

al1EnfuturEs!

ssh -L 2013:localhost:80 dnguyen@polaris.biol.mcgill.ca
2dock
docker-compose up -d
localhost:2013

PRISM website SSH
  prismres@prism.research.mcgill.ca
  XLRB]4#.1#3K

https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

# WEDNESDAY
  Download everything and put on HDD for myself
  Finalize s2bak review

# LATER
  S2BAK
    Test predictive performance to see if things are working as intended
      Need to demonstrate that the package is working as intended.
    Issues
      Check scaling? Where are we doing it? Should we?
      Assumes `type = response` for predict function... if that function does not have it then we will have big problem
        Maybe separate it into lists? But does it HAVE to be type = "response"?
          e.g., fit.args = list(...) and pred.args = list(..)
        How to we ensure that this works?
          Assume default type = response, but if it breaks then user needs to provide their own arg.
    Concerns
      Test the addSurvey feature and make sure it works with lists and formulas
        Also check to see if it works with only some formulas having `survey_var`
        Need to ensure the addition of `so` is working as intended.
      Summary is not very useful, especially because the "Call" is super long
        Should be edited or used in a more thoughtful way
        The skeleton is there for editing though
      Need to make sure readout backend is as optimized as possible
        Maybe we make sure doReadout for predict auto-detects (but can be forced on way or another) - double check!
        CRAN policy ensure that external changes are not made without user permission
          Therefore we need to make sure it's not possible for the user to accidentally do something bad
      Replace 1: with seq_len?
        Deals with empty edge case (but also maybe better coding practice)
      Double check index stuff
        Consider makling the index checking stuff its own function
        Ensure that we are matching sites/species correctly even if things are in weird orders
        `ind` stuff seems not well done S2BaK wrapper,
      Check trait imputation
        What's going on here?
    At some point we need to make a full checklist for publication to CRAN
      Look also in to the testing procedures for the package to make sure it works on all operating systems, etc.
      Look into how to write vignettes and other things that need to be created for the package
      https://r-pkgs.org/release.html
      https://www.mzes.uni-mannheim.de/socialsciencedatalab/article/r-package/#section4
    New features to add
      Start vignette, write notes
        Tutorial guide (flowchart as figure?)
          s2bak example as PowerPoint or document
            Graphical workflow
          https://github.com/VangiElia/GEDI4R
          What does the data look like, and what can you do with it with s2bak
          Embed into markdown
      Add examples again after finalizing the functions
        @example field
        CTRL K + CTRL C in VSCode to comment blocks
      Allow providing additional arguments seperately per modelling argument?
        So the user can have different modelling approaches per user
        https://stackoverflow.com/questions/71595861/how-to-pass-multiple-different-arguments-to-a-set-of-parameters-in-r-functions
      Fit survey-only models as well?
        We have the option for S2, SO but not with just survey
        Maybe as an argument within the S2 model?
      Adding cross-validation as a function option?
        Doing 10-fold CV
      s2bakSim: Add environment for `bias` thing?
        Like something to feel like distance to road
        This would work better for example
      Fitting S2BaK with MaxEnt (maxnet and ecospat?)
        Re-do the one we have now
        See BIAB for more details
